{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational_Principal_Components-PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shainedl/Papers-Colab/blob/master/Variational_Principal_Components_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWamupqWQXfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.distributions as tdist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L50MQamPPB_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BayesianPCA():\n",
        "  \n",
        "  def __init__(self, a_alpha=10e-3, b_alpha=10e-3, a_tau=10e-3, b_tau=10e-3, beta=10e-3):\n",
        "    \n",
        "    # hyperparameters\n",
        "    self.a_alpha = a_alpha\n",
        "    self.b_alpha = b_alpha\n",
        "    self.a_tau = a_tau\n",
        "    self.b_tau = b_tau\n",
        "    self.beta = beta \n",
        "     \n",
        "  def __reestimate(self):\n",
        "    \"\"\"\n",
        "    Cycle through the groups of variables in turn to re-estimate each distribution \n",
        "    \"\"\"\n",
        "    \n",
        "    # observation parameter\n",
        "    self.tau = self.a_tau_tilde / self.b_tau_tilde\n",
        "\n",
        "    # latent variables\n",
        "    self.sigma_x = torch.inverse(torch.eye(self.q) + self.tau *\n",
        "                   (torch.trace(self.sigma_w) + torch.mm(self.mean_w.T, self.mean_w)))\n",
        "    self.mean_x = self.tau * torch.mm(torch.mm(self.sigma_x, self.mean_w.T),(self.t_n - self.mean_mu))\n",
        "    \n",
        "    # observation parameter                                \n",
        "    self.sigma_mu = torch.eye(self.d) / (self.beta + self.N * self.tau)\n",
        "    w_x = torch.mm(self.mean_w, self.mean_x)\n",
        "    sum = 0\n",
        "    for n in range(self.N):\n",
        "      sum += torch.sub(self.t_n[:,n], w_x[:,n])\n",
        "    self.mean_mu = self.tau * torch.mm(self.sigma_mu, torch.reshape(sum, (-1,1)))\n",
        "        \n",
        "    # hyperparameter controlling the columns of W\n",
        "    self.alpha = self.a_alpha_tilde / self.b_alpha_tilde\n",
        "                                     \n",
        "    # weight                                 \n",
        "    self.sigma_w = torch.inverse(torch.diag(self.alpha) + self.tau * \n",
        "                   (self.N * self.sigma_x + torch.mm(self.mean_x, self.mean_x.t())))\n",
        "    self.mean_w = (self.tau * torch.mm(self.mean_x, (torch.sub(self.t_n.t(), self.mean_mu.t())))).t()\n",
        "   \n",
        "    # alpha's gamma distribution parameter                            \n",
        "    self.b_alpha_tilde = self.b_alpha + 0.5 * (torch.trace(self.sigma_w) + torch.diag(torch.mm(self.mean_w.t(), self.mean_w)))                                                     \n",
        "    # tau's gamma distribution parameter     \n",
        "    self.b_tau_tilde = torch.tensor([self.b_tau + 0.5 * torch.sum(torch.mm(self.t_n.t(), self.t_n)) + \\\n",
        "                       0.5 * self.N * (torch.trace(self.sigma_mu) + torch.dot(self.mean_mu.flatten(), self.mean_mu.flatten()))+ \\\n",
        "                       0.5 * torch.trace(torch.mm(torch.trace(self.sigma_w) + \\\n",
        "                       torch.mm(self.mean_w.t(), self.mean_w), self.N * self.sigma_x + \\\n",
        "                       torch.mm(self.mean_x, self.mean_x.t()))) + \\\n",
        "                       torch.sum(torch.mm(torch.mm(self.mean_mu.t(), self.mean_w), self.mean_x)) - \\\n",
        "                       torch.sum(torch.mm(torch.mm(self.t_n.t(), self.mean_w), self.mean_x)) - \\\n",
        "                       torch.sum(torch.mm(self.t_n.t(), self.mean_mu))])      \n",
        "    \n",
        "  def fit(self, t_n, iterations = 1000, threshold = 1.0):\n",
        "    \"\"\"\n",
        "    Fits the data\n",
        "    \n",
        "    Parameters \n",
        "    ----------\n",
        "    t_n : d x N matrix\n",
        "      observed data to be fit\n",
        "      \n",
        "    iterations: int\n",
        "      number of iterations to re-estimate the lower bound\n",
        "    \n",
        "    threshold: float\n",
        "      determines convergence\n",
        "      \n",
        "    \"\"\"\n",
        "    self.t_n = t_n\n",
        "    self.d = self.t_n.shape[0]                     \n",
        "    self.q = self.d - 1\n",
        "    self.N = self.t_n.shape[1]   \n",
        "    \n",
        "    # variational parameters\n",
        "    self.mean_x = torch.randn(self.q, self.N)\n",
        "    self.sigma_x = torch.eye(self.q)\n",
        "    self.mean_mu = torch.randn(self.d, 1)\n",
        "    self.sigma_mu = torch.eye(self.d)\n",
        "    self.mean_w = torch.randn(self.d, self.q)\n",
        "    self.sigma_w = torch.eye(self.q)\n",
        "    self.a_alpha_tilde = self.a_alpha + self.d / 2\n",
        "    self.b_alpha_tilde = torch.abs(torch.randn(self.q))  \n",
        "    self.a_tau_tilde = self.a_tau + self.N * self.d / 2\n",
        "    self.b_tau_tilde = torch.abs(torch.randn(1))\n",
        "    \n",
        "    for i in range(iterations):\n",
        "      self.__reestimate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdhtVGJWuKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "We generate 100 data points in d = 10 dimensions from a Gaussian distribution \n",
        "having standard deviations of (5, 4, 3, 2) along four orthogonal directions \n",
        "and a standard deviation of 1 in the remaining five directions\n",
        "\"\"\"\n",
        "m = tdist.multivariate_normal.MultivariateNormal(torch.zeros(10), torch.diag(torch.Tensor([5,4,3,2,1,1,1,1,1,1])))\n",
        "X = m.sample(sample_shape=torch.Size([100])).t()\n",
        "\"\"\"\n",
        "Hinton diagram of <W> from variational Bayesian PCA \n",
        "\"\"\"\n",
        "test = BayesianPCA()\n",
        "test.fit(X) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co77O078nlrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}