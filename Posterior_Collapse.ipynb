{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Posterior_Collapse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shainedl/Papers-Colab/blob/master/Posterior_Collapse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Mg5TYiaI7D",
        "colab_type": "code",
        "outputId": "d6ef0b64-5dbf-4922-977f-55f6d4ca46e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from google.colab import files\n",
        "from collections import defaultdict\n",
        "from itertools import count, chain\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pdb\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU1ksCbwaOjT",
        "colab_type": "code",
        "outputId": "18ea3ab0-fc4a-4e96-f9fd-ad6c03bf6c1f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded_training = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad5f9ea3-bc99-41bd-a0df-bd33b793d1da\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ad5f9ea3-bc99-41bd-a0df-bd33b793d1da\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_train.txt to sample_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_3MgQC5aVpG",
        "colab_type": "code",
        "outputId": "6300491a-ea84-4633-cf92-26b61f7f8733",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded_val = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de11db21-6af1-4a0b-b6d3-005aa6f93bd6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-de11db21-6af1-4a0b-b6d3-005aa6f93bd6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_dev.txt to sample_dev.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygvyxibDahEP",
        "colab_type": "code",
        "outputId": "63f7ed11-e188-4ec0-de6c-ec63d9eda101",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "uploaded_test = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a685e465-5c44-4ec8-802e-1d4bf36ccb71\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a685e465-5c44-4ec8-802e-1d4bf36ccb71\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_test.txt to sample_test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR1DMUXiammS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file):\n",
        "  \"\"\"\n",
        "  Load training data and output vocabulary dictionaries\n",
        "  \"\"\"\n",
        "  w2i = defaultdict(lambda x=count(0): next(x))\n",
        "  w2i[\"<s>\"] \n",
        "  w2i[\"</s>\"] \n",
        "  w2i[\"<unk>\"] \n",
        "  w2i['<unk>twoDigitNum']\n",
        "  w2i['<unk>fourDigitNum']\n",
        "  w2i['<unk>containsDigitAndAlpha']\n",
        "  w2i['<unk>containsDigitAndDash']\n",
        "  w2i['<unk>containsDigitAndSlash']\n",
        "  w2i['<unk>containsDigitAndComma']\n",
        "  w2i['<unk>containsDigitAndPeriod']\n",
        "  w2i['<unk>othernum']\n",
        "  w2i['<unk>allCaps']\n",
        "  w2i['<unk>initCap']\n",
        "  w2i['<unk>lowercase']\n",
        "  w2i['<unk>time']\n",
        "  data = []\n",
        "  file = file.decode('utf-8')\n",
        "  sentences = file.splitlines()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    tokens = word_tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      w2i[token]\n",
        "    data.append(tokens)\n",
        "\n",
        "  freq_dist = nltk.FreqDist([item for sublist in data for item in sublist])\n",
        "  freq1 = set(list(freq_dist.keys())[-4000:])\n",
        "\n",
        "  w2i = dict(w2i)\n",
        "  for key in list(w2i.keys()):\n",
        "    if key in freq1:\n",
        "      w2i.pop(key)\n",
        "  i2w = {i:w for w,i in w2i.items()}\n",
        "\n",
        "  return data, w2i, i2w, freq_dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqelmnoMayFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data, w2i, i2w, freq_dist = load_data(uploaded_training['sample_train.txt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuOoLPZEaz_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_test(file):\n",
        "  \"\"\"\n",
        "  Load test and validation data\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  file = file.decode('utf-8')\n",
        "  sentences = file.splitlines()\n",
        "\n",
        "  for sentence in sentences:\n",
        "    tokens = word_tokenize(sentence)\n",
        "    data.append(tokens)\n",
        "    \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDw28--RikE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = load_data_test(uploaded_val['sample_dev.txt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRPrdosha2jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = load_data_test(uploaded_test['sample_test.txt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaRH-yBsa3eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = [to_ix[\"<s>\"]]\n",
        "  for w in seq:\n",
        "    if w in to_ix:\n",
        "      idxs.append(to_ix[w])\n",
        "    else:\n",
        "      unk = get_word_class(w)\n",
        "      idxs.append(to_ix[unk])\n",
        "  idxs.append(to_ix[\"</s>\"])\n",
        "  return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-o0z6Faa40z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_class(x):\n",
        "    \"\"\"\n",
        "    Get fword class for a given word.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : str\n",
        "        word to be replaced\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        corresponding word class\n",
        "    \"\"\"\n",
        "    if re.fullmatch(r'[0-9]{2}', x):\n",
        "        return '<unk>twoDigitNum'\n",
        "    elif re.fullmatch(r'[0-9]{4}', x):\n",
        "        return '<unk>fourDigitNum'\n",
        "    elif re.fullmatch(r'A[0-9\\-]+', x):\n",
        "        return '<unk>containsDigitAndAlpha'\n",
        "    elif re.fullmatch(r'[0-9]+\\-[0-9]+', x):\n",
        "        return '<unk>containsDigitAndDash'\n",
        "    elif re.fullmatch(r'[0-9]+/[0-9]+/[0-9]+', x):\n",
        "        return '<unk>containsDigitAndSlash'\n",
        "    elif re.fullmatch(r'([0-9]+,[0-9]+)+\\.[0-9]+', x):\n",
        "        return '<unk>containsDigitAndComma'\n",
        "    elif re.fullmatch(r'[0-9]+\\.[0-9]+', x):\n",
        "        return '<unk>containsDigitAndPeriod'\n",
        "    elif re.fullmatch(r'[0-9]+', x):\n",
        "        return '<unk>othernum'\n",
        "    elif re.fullmatch(r'[A-Z]+', x):\n",
        "        return '<unk>allCaps'\n",
        "    elif re.fullmatch(r'[A-Z][a-z]+', x):\n",
        "        return '<unk>initCap'\n",
        "    elif re.fullmatch(r'[a-z]+', x):\n",
        "        return '<unk>lowercase'\n",
        "    elif re.match(r'[0-9]+:[0-9]+', x):\n",
        "        return '<unk>time'\n",
        "\n",
        "    return '<unk>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYbg1MLFa6Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_data(batch_size, data, w2i):\n",
        "  \"\"\"\n",
        "  Batches data with sequences of the same length\n",
        "  \"\"\"\n",
        "  sentence_lengths = np.array([len(sentence) for sentence in data])\n",
        "  sorted_idx = np.argsort(sentence_lengths)\n",
        "  sorted_lengths = sentence_lengths[sorted_idx]\n",
        "\n",
        "  len_increase_idx = []\n",
        "  for i in range(1, len(sorted_lengths)):\n",
        "    if sorted_lengths[i] > sorted_lengths[i-1]:\n",
        "      len_increase_idx.append(i)\n",
        "  len_increase_idx.append(len(sorted_lengths))\n",
        "\n",
        "  batch_data = []\n",
        "  curr_idx = 0\n",
        "  for i, idx in enumerate(len_increase_idx):\n",
        "    while curr_idx < idx:\n",
        "      batch_sentences = []\n",
        "      new_idx = min(curr_idx + batch_size, idx)\n",
        "      for i in range(curr_idx, new_idx):\n",
        "        sent_to_vec = prepare_sequence(data[sorted_idx[i]], w2i)\n",
        "        batch_sentences.append(sent_to_vec)\n",
        "      curr_idx = new_idx\n",
        "      batch_sentences = torch.stack(batch_sentences).to(device=cuda)\n",
        "      batch_data.append(batch_sentences)\n",
        "\n",
        "  i = 0\n",
        "  j = len(batch_data)\n",
        "  while i < j:\n",
        "    if i != 0 and len(batch_data[i]) <= 2 and len(batch_data[i][0]) == len(batch_data[i-1][0]):\n",
        "      batch_data.append(torch.cat((batch_data[i], batch_data[i-1])))\n",
        "      batch_data.pop(i)\n",
        "      batch_data.pop(i-1)\n",
        "      i -= 1\n",
        "      j = len(batch_data)\n",
        "    elif len(batch_data[i]) == 1:\n",
        "      batch_data.pop(i)\n",
        "      j = len(batch_data)\n",
        "    else:\n",
        "      i += 1\n",
        "\n",
        "  return batch_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPzqSwHIa8a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hO_2lWKa9zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True\n",
        "cuda = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKZ1Kuj0a_PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_training = batch_data(batch_size, training_data, w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOF1ngl1bAQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_val = batch_data(batch_size, val_data, w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPUl_RdxbBMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_test = batch_data(batch_size, test_data, w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiqQIDEZbDDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size, latent_size):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                   embedding_dim=embedding_size)\n",
        "    \n",
        "    self.rnn = nn.LSTM(input_size=embedding_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    self.fc_mu = nn.Linear(hidden_size, latent_size)\n",
        "    self.fc_var = nn.Linear(hidden_size, latent_size)\n",
        "\n",
        "    self._initialize_parameters([-0.01, 0.01], [-0.1, 0.1]) \n",
        "\n",
        "  def encode(self, x):\n",
        "    \"\"\"\n",
        "    Produces a Gaussian distribution over the possible values of the code z \n",
        "    from which x could have been generated\n",
        "        \n",
        "    Parameters\n",
        "    ----------\n",
        "      x: batch size x sequence length Tensor\n",
        "        observed data\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      mu: batch size x latent size Tensor\n",
        "        mean of Gaussian distribution\n",
        "        \n",
        "      logvar: batch size x latent size Tensor\n",
        "        log of variance of Gaussian distribution     \n",
        "    \"\"\"\n",
        "    x = self.embeddings(x)\n",
        "    outputs, (hidden, cell) = self.rnn(x)\n",
        "    mu = self.fc_mu(hidden)\n",
        "    logvar = self.fc_var(hidden)\n",
        "    mu = mu.squeeze()\n",
        "    logvar = logvar.squeeze()\n",
        "    return mu, logvar \n",
        "\n",
        "  def _initialize_parameters(self, lstm_init, embed_init):\n",
        "    \"\"\"\n",
        "    Initializes the LSTM parameters and embeddings with uniform distributions\n",
        "    \"\"\"\n",
        "    for param in self.parameters():\n",
        "      nn.init.uniform_(param, a=lstm_init[0], b=lstm_init[1])\n",
        "    nn.init.uniform_(self.embeddings.weight, a=embed_init[0], b=embed_init[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp6lE4_XbEQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size, latent_size):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                   embedding_dim=embedding_size)\n",
        "    \n",
        "    self.rnn = nn.LSTM(input_size=embedding_size + latent_size,\n",
        "                        hidden_size=hidden_size,\n",
        "                        batch_first=True)    \n",
        "\n",
        "    self.fc_hid = nn.Linear(latent_size, hidden_size, bias=False)\n",
        "    self.fc_voc = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    self.dropout = nn.Dropout()\n",
        "    self._initialize_parameters([-0.01, 0.01], [-0.1, 0.1])\n",
        "\n",
        "  def decode(self, z, inputs, nsample=1):\n",
        "    \"\"\"\n",
        "    Given a code z it produces unscaled output corresponding to the vocabulary\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      z: batch size x latent size Tensor\n",
        "        latent variables\n",
        "      \n",
        "      inputs: batch size x sequence length Tensor\n",
        "        source sequence\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      output_logits: batch size x sequence length x vocab size Tensor\n",
        "        unscaled output\n",
        "    \"\"\"\n",
        "    embed = self.embeddings(inputs)\n",
        "    embed = self.dropout(embed)\n",
        "    if nsample > 1:\n",
        "      seq_len = embed.size(1)\n",
        "      batch_size, nsamples, latent_size = z.size()\n",
        "      z_exp = z.expand(seq_len, batch_size, nsamples, latent_size)\n",
        "      z_exp = z_exp.transpose(1,0)\n",
        "      z_exp = z_exp.transpose(2,1)\n",
        "      z_exp = z_exp.view(batch_size * nsamples, seq_len, latent_size)\n",
        "      embed = embed.expand(nsamples, batch_size, seq_len, embedding_size)\n",
        "      embed = embed.reshape(batch_size * nsamples, seq_len, embedding_size)\n",
        "    else:\n",
        "      z_exp = z.expand(embed.size(1), z.size(0), z.size(1))\n",
        "      z_exp = z_exp.transpose(1,0)\n",
        "    embed_lat = torch.cat((embed, z_exp), 2)\n",
        "    if nsample > 1:\n",
        "      z = z.view(batch_size * nsamples, latent_size)\n",
        "    cell = self.fc_hid(z)\n",
        "    cell = cell.unsqueeze(0)\n",
        "    hidden = torch.tanh(cell)\n",
        "\n",
        "    outputs, (hidden, cell) = self.rnn(embed_lat, (hidden, cell))\n",
        "    outputs = self.dropout(outputs)\n",
        "    output_logits = self.fc_voc(outputs)\n",
        "    return output_logits\n",
        "\n",
        "  def decode_greedy(self, z, inputs):\n",
        "    \"\"\"\n",
        "    Given a code z it produces unscaled output corresponding to the vocabulary\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      z: 1 x latent size Tensor\n",
        "        latent variables sampled from prior\n",
        "      \n",
        "      inputs: 1 x 1 Tensor\n",
        "        start token\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "      batch_decoded: output sequence length list\n",
        "        decoded output sequence\n",
        "    \"\"\"\n",
        "    cell = self.fc_hid(z)\n",
        "    cell = cell.unsqueeze(0)\n",
        "    hidden = torch.tanh(cell)\n",
        "\n",
        "    input_d = inputs\n",
        "    output_logit_prev = None\n",
        "    batch_decoded = []\n",
        "    z = z.unsqueeze(0)\n",
        "\n",
        "    counter = 0\n",
        "    while counter < 50:\n",
        "      embed = self.embeddings(input_d)\n",
        "      if counter > 0:\n",
        "        z = torch.cat((z, z[0][0].unsqueeze(0).unsqueeze(0)), 1)\n",
        "      embed_lat = torch.cat((embed, z), 2)\n",
        "      outputs, (hidden, cell) = self.rnn(embed_lat, (hidden, cell))  \n",
        "      output_logit = self.fc_voc(outputs)\n",
        "      max_token = torch.argmax(output_logit, dim=2).flatten()\n",
        "      if max_token[-1].item() == w2i[\"</s>\"]:\n",
        "        break\n",
        "      batch_decoded.append(i2w[max_token[-1].item()])\n",
        "      input_d = torch.cat((input_d, max_token[-1].unsqueeze(0).unsqueeze(0)), 1)\n",
        "      counter += 1\n",
        "    \n",
        "    return batch_decoded\n",
        "\n",
        "  def _initialize_parameters(self, lstm_init, embed_init):\n",
        "    \"\"\"\n",
        "    Initializes the LSTM parameters and embeddings with uniform distributions\n",
        "    \"\"\"\n",
        "    for param in self.parameters():\n",
        "      nn.init.uniform_(param, a=lstm_init[0], b=lstm_init[1])\n",
        "    nn.init.uniform_(self.embeddings.weight, a=embed_init[0], b=embed_init[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG9GSLxPbFuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(VAE, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.re_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "  def forward(self, x, greedy=False):\n",
        "    \"\"\"\n",
        "    Forward pass of the model \n",
        "    \"\"\"\n",
        "    mu, logvar = self.encoder.encode(x)\n",
        "    kl = self.get_kl(mu, logvar)\n",
        "    z = self._reparameterize(mu, logvar)\n",
        "\n",
        "    source = x[:,:-1]\n",
        "    target = x[:, 1:]\n",
        "    if greedy:\n",
        "      output_logits, batch_decoded = self.decoder.decode_greedy(z, source)\n",
        "      re = self.get_reconstruction_error(output_logits, target)\n",
        "      return kl, re, batch_decoded\n",
        "    else: \n",
        "      output_logits = self.decoder.decode(z, source)\n",
        "      re = self.get_reconstruction_error(output_logits, target)\n",
        "      return kl, re\n",
        "\n",
        "  def _reparameterize(self, mu, logvar, nsamples=1):\n",
        "    \"\"\"\n",
        "    Reparameterize the random variable z to express as a deterministic variable\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "      mu: batch size x latent size Tensor\n",
        "        mean of Gaussian distribution\n",
        "        \n",
        "      logvar: batch size x latent size Tensor\n",
        "        log of variance of Gaussian distribution     \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "      z: batch size x latent size Tensor\n",
        "        reparameterization of latent variables\n",
        "    \"\"\"\n",
        "    std = torch.exp(logvar / 2)\n",
        "    \n",
        "    if nsamples > 1:\n",
        "      batch_size, latent_size = mu.size()\n",
        "      mu = mu.expand(nsamples, batch_size, latent_size)\n",
        "      mu = mu.transpose(1,0)\n",
        "      std = std.expand(nsamples, batch_size, latent_size)\n",
        "      std = std.transpose(1,0)\n",
        "\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + std * eps  \n",
        "\n",
        "  def get_kl(self, mu, logvar):\n",
        "    \"\"\"\n",
        "    Returns the KLD between posterior and prior\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      mu: batch size x latent size Tensor\n",
        "        mean of Gaussian distribution\n",
        "        \n",
        "      logvar: batch size x latent size Tensor\n",
        "        log of variance of Gaussian distribution\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "      kl: batch size x latent size Tensor\n",
        "        kl divergence\n",
        "    \"\"\"\n",
        "    return (mu**2 + logvar.exp() - 1 - logvar) / 2\n",
        "\n",
        "  def get_reconstruction_error(self, output_logits, target):\n",
        "    \"\"\"\n",
        "    Returns the reconstruction error\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      output_logits: batch size x sequence length x vocab size Tensor\n",
        "        unscaled output\n",
        "      \n",
        "      target: batch size x sequence length Tensor\n",
        "        target sequence\n",
        "    \"\"\"\n",
        "    output_logits = output_logits.view(-1, output_logits.size(2))\n",
        "    target = target.contiguous().view(-1)\n",
        "    return self.re_loss(output_logits, target)\n",
        "\n",
        "  def importance_sampling(self, x, K, nsamples):\n",
        "    \"\"\"\n",
        "    Helpful Link: http://paulrubenstein.co.uk/deriving-the-variational-lower-bound/\n",
        "\n",
        "    Returns the negative log likehood approximation using importance sampling\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "      x: batch size x sequence length Tensor\n",
        "        observed data\n",
        "\n",
        "      K: int\n",
        "        number of total samples\n",
        "\n",
        "      nsamples: int\n",
        "        number of samples at each iteration\n",
        "\n",
        "    \"\"\"\n",
        "    mu, logvar = self.encoder.encode(x)\n",
        "    mu_un = mu.unsqueeze(1)\n",
        "    logvar_un = logvar.unsqueeze(1) \n",
        "    \n",
        "    loss = []\n",
        "    for k in range(int(K / nsamples)):\n",
        "      z = self._reparameterize(mu, logvar, nsamples)\n",
        "      logq_zx = -0.5 * (mu_un.size(2) * math.log(2 * math.pi) + logvar_un.sum(dim=-1)) \\\n",
        "                - 0.5 * ((z - mu_un)**2 / (logvar_un.exp())).sum(dim=-1)\n",
        "      logp_z = (-0.5 * math.log(2 * math.pi) - z**2 / 2).sum(dim=-1)\n",
        "      kl = logq_zx - logp_z\n",
        "\n",
        "      source = x[:,:-1]\n",
        "      target = x[:, 1:]\n",
        "      batch_size, seq_len = target.size()\n",
        "      target = target.expand(nsamples, batch_size, seq_len)\n",
        "      target = target.transpose(1,0)\n",
        "      output_logits = self.decoder.decode(z, source, nsamples)\n",
        "      re = self.get_reconstruction_error(output_logits, target)      \n",
        "      re = re.view(batch_size, nsamples, -1).sum(dim=-1)\n",
        "\n",
        "      loss.append(-re - kl)\n",
        "\n",
        "    ll = torch.stack(loss,1).view(batch_size,-1).logsumexp(-1) - math.log(K)\n",
        "    nll = -ll\n",
        "    return nll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJRMfmJIbHcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(w2i)\n",
        "embedding_size = 128\n",
        "hidden_size = 512 \n",
        "latent_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBa3KOvZbI7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_every = round(len(batch_training) / batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD2w4eBnbNWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecayLearning:\n",
        "  \"\"\"\n",
        "  Class updated from https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "  \"\"\"\n",
        "  def __init__(self, patience=2):\n",
        "    self.patience = patience\n",
        "    self.counter = 0\n",
        "    self.best_score = None\n",
        "    self.update_lr = False\n",
        "\n",
        "  def __call__(self, val_loss):\n",
        "    score = -val_loss\n",
        "\n",
        "    if self.best_score is None:\n",
        "      self.best_score = score\n",
        "    elif score < self.best_score:\n",
        "      self.counter += 1\n",
        "      if self.counter >= self.patience:\n",
        "        self.update_lr = True\n",
        "    else:\n",
        "      self.best_score = score\n",
        "      self.counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpZjLw7-hUz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate(latent_size, sample1, sample2):\n",
        "  \n",
        "  for w in range(11):\n",
        "    weight = w * 0.1\n",
        "    sample = weight * sample2 + (1-weight) * sample1\n",
        "    batch_decoded = decoder.decode_greedy(sample, torch.zeros(1, dtype=torch.long, device=cuda).unsqueeze(0))\n",
        "    print(*batch_decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS9bGdlsb5YH",
        "colab_type": "text"
      },
      "source": [
        "Pre-training on Autoencoder objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saVwTKzDc3eq",
        "colab_type": "text"
      },
      "source": [
        "Pre-training ran for 3 hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGrbRCtRbKgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "  \"\"\"\n",
        "  Trains the model\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for batch_idx, data in enumerate(batch_training):\n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    re = model(data)\n",
        "    loss = re\n",
        "    loss.backward()\n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    running_loss += loss\n",
        "  \n",
        "    if (epoch == 0 or epoch % 10 == 9) and batch_idx % print_every == print_every-1:    \n",
        "      print('[%d, %5d] Train loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / print_every))\n",
        "      running_loss = 0.0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHxkIzObLqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(epoch, validation=False):\n",
        "  \"\"\"\n",
        "  Run the model on validation or test dataset\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  anneal = 0.1 * epoch if epoch < 10 else 1.0\n",
        "\n",
        "  data = batch_val if validation else batch_test\n",
        "  running_loss = 0.0\n",
        "  for batch_idx, data in enumerate(data):\n",
        "    _, re = model(data)\n",
        "    running_loss += re.sum().item()\n",
        "\n",
        "  avg_loss = running_loss / (batch_idx + 1)\n",
        "  if validation and (epoch == 0 or epoch % 10 == 9):\n",
        "    print('[%d, %5d] Validation loss: %.3f' % (epoch + 1, batch_idx + 1, avg_loss))\n",
        "  else:\n",
        "    print('[%d, %5d] Test loss: %.3f' % (epoch + 1, batch_idx + 1, avg_loss))\n",
        "\n",
        "  return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dxpRu1LbSaA",
        "colab_type": "code",
        "outputId": "430fd20c-33aa-4954-ed8c-9194c6e04c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "decoder = Decoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "model = VAE(encoder, decoder)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  \n",
        "lr = 0.5\n",
        "optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "\n",
        "decay_learning = DecayLearning()\n",
        "num_decays = 0\n",
        "early_stop = 5\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(epoch)\n",
        "  val_loss = test(epoch, True)\n",
        "  decay_learning(val_loss)\n",
        "  if decay_learning.update_lr:\n",
        "    lr *= 0.5\n",
        "    num_decays += 1\n",
        "    if num_decays == early_stop + 1:\n",
        "      print(\"Stopping early at epoch\", epoch+1)\n",
        "      break\n",
        "    print(\"Learning rate has been decayed to\", lr, \"at epoch\", epoch+1)\n",
        "    optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    decay_learning = DecayLearning()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3125] Train loss: 3.947\n",
            "[1,  6250] Train loss: 3.595\n",
            "[1,  9375] Train loss: 3.789\n",
            "[1, 12500] Train loss: 3.809\n",
            "[1,  1248] Validation loss: 4.795\n",
            "Learning rate has been decayed to 0.25 at epoch 4\n",
            "[10,  3125] Train loss: 1.061\n",
            "[10,  6250] Train loss: 1.135\n",
            "[10,  9375] Train loss: 1.453\n",
            "[10, 12500] Train loss: 1.745\n",
            "[10,  1248] Validation loss: 2.527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV6lmdwQhxKH",
        "colab_type": "code",
        "outputId": "da67386e-9564-4c69-9ce6-957550bd2cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# epoch in range(10,20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.125 at epoch 17\n",
            "[20,  3125] Train loss: 0.276\n",
            "[20,  6250] Train loss: 0.382\n",
            "[20,  9375] Train loss: 0.614\n",
            "[20, 12500] Train loss: 0.917\n",
            "[20,  1248] Validation loss: 2.240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHlKxzZ7pDqn",
        "colab_type": "code",
        "outputId": "3000eacc-df6a-417e-9e30-105968b243e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# epoch in range(20,30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.0625 at epoch 23\n",
            "[30,  3125] Train loss: 0.136\n",
            "[30,  6250] Train loss: 0.214\n",
            "[30,  9375] Train loss: 0.391\n",
            "[30, 12500] Train loss: 0.666\n",
            "[30,  1248] Validation loss: 1.204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fFbie1ywMoz",
        "colab_type": "code",
        "outputId": "da4ec794-681d-4ad6-d1af-b5323f6fcb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# epoch in range(30,40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.03125 at epoch 32\n",
            "[40,  3125] Train loss: 0.096\n",
            "[40,  6250] Train loss: 0.158\n",
            "[40,  9375] Train loss: 0.311\n",
            "[40, 12500] Train loss: 0.554\n",
            "[40,  1248] Validation loss: 0.786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tafSVIN829PI",
        "colab_type": "code",
        "outputId": "ec59506a-1b7d-47e1-8b9e-0ba83a109ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# epoch in range(40,50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.015625 at epoch 43\n",
            "[50,  3125] Train loss: 0.081\n",
            "[50,  6250] Train loss: 0.137\n",
            "[50,  9375] Train loss: 0.273\n",
            "[50, 12500] Train loss: 0.504\n",
            "[50,  1248] Validation loss: 0.678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMU44-dfUYzs",
        "colab_type": "code",
        "outputId": "de7ae0fd-64cc-4484-f375-dd0de2e1c65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# epoch in range(50,60):"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping early at epoch 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghvZ8qU-kyVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "119ffda4-5e80-4066-ba47-ddaf1485ef72"
      },
      "source": [
        "test(57, False)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[58,  1249] Test loss: 27.076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.07570124245148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7GtKwiZnAea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NyWjK0YnDad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v67cHTrenFqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "cd6c4366-af08-4d69-e699-3e9714ae2644"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>initCap teacher performs basketball\n",
            "<unk>initCap teacher performs basketball\n",
            "<unk>initCap teacher performs with\n",
            "<unk>initCap teacher giving a\n",
            "Boy 's has a ball\n",
            "Boy 's has a kids\n",
            "Boy 's has a bird\n",
            "Man 's time a store\n",
            "Person 's making a store .\n",
            "Person with ready a field .\n",
            "Person with ready a field .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MUs1Br8naBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNrEwBrIncEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVzR1UX7nd3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2d7e212e-9542-4908-8b94-6bbac5bed727"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two are near .\n",
            "Two are near .\n",
            "Two are <unk>lowercase\n",
            "Three are <unk>lowercase\n",
            "Men and <unk>lowercase table\n",
            "Workers and <unk>lowercase a man\n",
            "Friends and <unk>lowercase a man\n",
            "people and <unk>lowercase a table\n",
            "people and <unk>lowercase a\n",
            "people and <unk>lowercase a\n",
            "There , and walking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcw7Hd_anlOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZdBzW_QnnYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruZVbf7rnpBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "dcdbe3a2-0aed-4e17-f8da-94432d1639f3"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Guy and friends in field\n",
            "Kid and friends in field\n",
            "Lady and friends in field .\n",
            "Boy and friends in field .\n",
            "Boy wearing work to .\n",
            "Two girls work with .\n",
            "Two girls work and .\n",
            "Two girls on each .\n",
            "Two girls on each .\n",
            "Two women jumping <unk>lowercase .\n",
            "A women jumping <unk>lowercase .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sin1b0HRETms",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g0gZhVfZmK_",
        "colab_type": "code",
        "outputId": "e7ef8654-191d-4341-b5c5-2feda9c93d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGelVF5YdNWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Helpful Link: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "\"\"\"\n",
        "model_save_name = 'pretraining.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Ivstgze1-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "encoder.load_state_dict(checkpoint['encoder'])\n",
        "decoder = Decoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "model = VAE(encoder, decoder)\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SnHpy3FWv9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(epoch, validation=False, target_rate = (4.0 / float(latent_size))):\n",
        "  \"\"\"\n",
        "  Run the model on validation or test dataset\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  data = batch_val if validation else batch_test\n",
        "  running_loss = running_kl = running_re = 0.0\n",
        "  num_words = num_seq = 0\n",
        "  for batch_idx, data in enumerate(data):\n",
        "    kl, re = model(data)\n",
        "    bath_, seq_len = data.size()\n",
        "    num_words += batch_size * (seq_len - 1)\n",
        "    num_seq += batch_size\n",
        "    running_kl += kl.sum()\n",
        "    running_re += re.sum()\n",
        "\n",
        "  avg_loss = (running_kl + running_re) / num_seq\n",
        "  avg_kl = running_kl / num_seq\n",
        "  avg_re = running_re / num_seq\n",
        "  if validation and (epoch == 0 or epoch % 10 == 9):\n",
        "    print('[%d, %5d] Validation loss: %.3f' % (epoch + 1, batch_idx + 1, avg_loss))\n",
        "    print('[%d, %5d] Validation KL: %.3f' % (epoch + 1, batch_idx + 1, avg_kl))\n",
        "    print('[%d, %5d] Validation RE: %.3f' % (epoch + 1, batch_idx + 1, avg_re))\n",
        "  elif not validation:\n",
        "    print('[%d, %5d] Test loss: %.3f' % (epoch + 1, batch_idx + 1, avg_loss))\n",
        "    print('[%d, %5d] Test KL: %.3f' % (epoch + 1, batch_idx + 1, avg_kl))\n",
        "    print('[%d, %5d] Test RE: %.3f' % (epoch + 1, batch_idx + 1, avg_re))\n",
        "    print('[%d, %5d] Test NLL: %.3f' % (epoch + 1, batch_idx + 1, avg_loss))\n",
        "    ppl = torch.exp((running_kl + running_re) / num_words)\n",
        "    print('[%d, %5d] Test PPL: %.3f' % (epoch + 1, batch_idx + 1, ppl))\n",
        "\n",
        "  return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfpVvKpWTrvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def importance_sampling_test():\n",
        "  model.eval()\n",
        "\n",
        "  data = batch_test \n",
        "  running_nll = 0.0\n",
        "  num_words = num_seq = 0\n",
        "  for batch_idx, data in enumerate(data):\n",
        "    nll = model.importance_sampling(data,500,50).sum().item()\n",
        "    batch_size, seq_len = data.size()\n",
        "    num_words += batch_size * (seq_len - 1)\n",
        "    num_seq += batch_size\n",
        "    running_nll += nll\n",
        "\n",
        "  final_nll = running_nll / num_seq\n",
        "  ppl = math.exp(running_nll / num_words)\n",
        "  print('Test NLL: %.3f' % (final_nll))\n",
        "  print('Test PPL: %.3f' % (ppl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgLwDbFH74qd",
        "colab_type": "text"
      },
      "source": [
        "Free Bits Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLIUepxtYkfn",
        "colab_type": "text"
      },
      "source": [
        "Free Bits ran for 1 and a half hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i98KAajfUX4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, target_rate=(4.0 / float(latent_size))):\n",
        "  \"\"\"\n",
        "  Trains the model\n",
        "  Helpful link for free bits: https://stats.stackexchange.com/questions/267924/explanation-of-the-free-bits-technique-for-variational-autoencoders\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  anneal = 0.1 * epoch if epoch < 10 else 1.0\n",
        "\n",
        "  running_loss = running_kl = running_re = 0.0\n",
        "  num_seq = 0\n",
        "  for batch_idx, data in enumerate(batch_training):\n",
        "    batch_size, seq_len = data.size()\n",
        "    num_seq += batch_size\n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    kl, re = model(data)\n",
        "    re_mean = re.view(batch_size, -1).mean(dim=0)\n",
        "    re_loss = re_mean.sum()\n",
        "    kl_mean = kl.mean(dim=0)\n",
        "    kl_mask = (kl_mean > target_rate).float()\n",
        "    fb_mask = (kl_mean <= target_rate).float()\n",
        "    free_b = kl_mask + target_rate\n",
        "    kl_fb = (kl_mean * kl_mask + free_b * fb_mask).sum()\n",
        "    loss = kl_fb * anneal + re_loss\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    running_kl += kl.sum()\n",
        "    running_re += re.sum()\n",
        "    running_loss += kl.sum() + re.sum()\n",
        "  \n",
        "    if (epoch == 0 or epoch % 10 == 9) and  batch_idx % print_every == print_every-1:    \n",
        "      print('[%d, %5d] Train loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / num_seq))\n",
        "      print('[%d, %5d] Train KL: %.3f' % (epoch + 1, batch_idx + 1, running_kl / num_seq))\n",
        "      print('[%d, %5d] Train RE: %.3f' % (epoch + 1, batch_idx + 1, running_re / num_seq))\n",
        "      running_loss = running_kl = running_re = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAfxKMwurYID",
        "colab_type": "code",
        "outputId": "ef0aa7f8-b3b8-4482-c242-f4bc0dbdaf56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "lr = 0.5\n",
        "optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "decay_learning = DecayLearning()\n",
        "num_decays = 0\n",
        "early_stop = 5\n",
        "clip_grad = 5.0\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(epoch)\n",
        "  val_loss = test(epoch, True)\n",
        "  decay_learning(val_loss)\n",
        "  if decay_learning.update_lr:\n",
        "    lr *= 0.5\n",
        "    num_decays += 1\n",
        "    if num_decays == early_stop + 1:\n",
        "      print(\"Stopping early at epoch\", epoch+1)\n",
        "      break\n",
        "    print(\"Learning rate has been decayed to\", lr, \"at epoch\", epoch+1)\n",
        "    optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    decay_learning = DecayLearning()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3125] Train loss: 127.056\n",
            "[1,  3125] Train KL: 119.090\n",
            "[1,  3125] Train RE: 7.966\n",
            "[1,  6250] Train loss: 63.078\n",
            "[1,  6250] Train KL: 56.953\n",
            "[1,  6250] Train RE: 6.125\n",
            "[1,  9375] Train loss: 43.746\n",
            "[1,  9375] Train KL: 36.464\n",
            "[1,  9375] Train RE: 7.282\n",
            "[1, 12500] Train loss: 35.303\n",
            "[1, 12500] Train KL: 27.303\n",
            "[1, 12500] Train RE: 8.000\n",
            "[1,  1248] Validation loss: 146.207\n",
            "[1,  1248] Validation KL: 120.718\n",
            "[1,  1248] Validation RE: 25.489\n",
            "[10,  3125] Train loss: 24.723\n",
            "[10,  3125] Train KL: 5.652\n",
            "[10,  3125] Train RE: 19.071\n",
            "[10,  6250] Train loss: 15.919\n",
            "[10,  6250] Train KL: 3.192\n",
            "[10,  6250] Train RE: 12.727\n",
            "[10,  9375] Train loss: 13.754\n",
            "[10,  9375] Train KL: 2.340\n",
            "[10,  9375] Train RE: 11.414\n",
            "[10, 12500] Train loss: 12.884\n",
            "[10, 12500] Train KL: 1.865\n",
            "[10, 12500] Train RE: 11.019\n",
            "[10,  1248] Validation loss: 45.523\n",
            "[10,  1248] Validation KL: 8.090\n",
            "[10,  1248] Validation RE: 37.434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk0xcKxAycmC",
        "colab_type": "code",
        "outputId": "665d8c22-58bb-44b9-9a2e-447c9317734d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# epoch in range(10,20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.25 at epoch 13\n",
            "[20,  3125] Train loss: 21.244\n",
            "[20,  3125] Train KL: 4.252\n",
            "[20,  3125] Train RE: 16.992\n",
            "[20,  6250] Train loss: 13.835\n",
            "[20,  6250] Train KL: 2.380\n",
            "[20,  6250] Train RE: 11.454\n",
            "[20,  9375] Train loss: 12.016\n",
            "[20,  9375] Train KL: 1.683\n",
            "[20,  9375] Train RE: 10.333\n",
            "[20, 12500] Train loss: 11.349\n",
            "[20, 12500] Train KL: 1.302\n",
            "[20, 12500] Train RE: 10.046\n",
            "[20,  1248] Validation loss: 41.028\n",
            "[20,  1248] Validation KL: 5.381\n",
            "[20,  1248] Validation RE: 35.647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUfqU4Wg2G8O",
        "colab_type": "code",
        "outputId": "fb02df61-023b-4a9e-f1e3-67bc7b7914f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# epoch in range(20,30):"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.125 at epoch 22\n",
            "Learning rate has been decayed to 0.0625 at epoch 25\n",
            "[30,  3125] Train loss: 19.931\n",
            "[30,  3125] Train KL: 4.241\n",
            "[30,  3125] Train RE: 15.689\n",
            "[30,  6250] Train loss: 12.676\n",
            "[30,  6250] Train KL: 2.328\n",
            "[30,  6250] Train RE: 10.348\n",
            "[30,  9375] Train loss: 11.080\n",
            "[30,  9375] Train KL: 1.650\n",
            "[30,  9375] Train RE: 9.430\n",
            "[30, 12500] Train loss: 10.416\n",
            "[30, 12500] Train KL: 1.295\n",
            "[30, 12500] Train RE: 9.120\n",
            "[30,  1248] Validation loss: 41.414\n",
            "[30,  1248] Validation KL: 5.076\n",
            "[30,  1248] Validation RE: 36.338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j094nqcW6uxS",
        "colab_type": "code",
        "outputId": "bf096a86-53ef-4fbc-8745-40ffcf5e17ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# epoch in range(30,40):"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.03125 at epoch 31\n",
            "Learning rate has been decayed to 0.015625 at epoch 37\n",
            "[40,  3125] Train loss: 20.112\n",
            "[40,  3125] Train KL: 4.295\n",
            "[40,  3125] Train RE: 15.816\n",
            "[40,  6250] Train loss: 12.550\n",
            "[40,  6250] Train KL: 2.330\n",
            "[40,  6250] Train RE: 10.221\n",
            "[40,  9375] Train loss: 10.884\n",
            "[40,  9375] Train KL: 1.651\n",
            "[40,  9375] Train RE: 9.233\n",
            "[40, 12500] Train loss: 10.272\n",
            "[40, 12500] Train KL: 1.297\n",
            "[40, 12500] Train RE: 8.975\n",
            "[40,  1248] Validation loss: 37.370\n",
            "[40,  1248] Validation KL: 4.883\n",
            "[40,  1248] Validation RE: 32.487\n",
            "Stopping early at epoch 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL7Kg1Gi9-41",
        "colab_type": "code",
        "outputId": "1184c016-28a8-42fd-fd85-6cf1bcc4ab10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "test(39, False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[40,  1249] Test loss: 36.809\n",
            "[40,  1249] Test KL: 4.838\n",
            "[40,  1249] Test RE: 31.971\n",
            "[40,  1249] Test NLL: 36.809\n",
            "[40,  1249] Test PPL: 47.397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(36.8093, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjQWAligqBc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "47f08d06-66d8-4d6e-9d2d-a06bb0e62bca"
      },
      "source": [
        "importance_sampling_test()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NLL: 36.496\n",
            "Test PPL: 45.989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGTvrgNb_1k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXqjfi-KArNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL1C1uTp_-io",
        "colab_type": "code",
        "outputId": "62e957ed-3366-4fae-c7b7-45e383c17c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A woman is standing next to a man , holding a knife .\n",
            "A woman is standing next to a man , holding a knife .\n",
            "A woman is standing next to a man , holding a knife .\n",
            "A woman is standing next to a man , holding a knife .\n",
            "A woman is standing next to a man , holding a knife .\n",
            "A woman is standing on a bench , holding a baby in her .\n",
            "A woman is standing on a bench , holding a baby in thought .\n",
            "A woman is standing on a bench , holding a baby in thought .\n",
            "A woman is standing on a bench , holding a baby in her .\n",
            "A woman is sitting on a bench , while others look on .\n",
            "A woman in a red shirt , is playing a game of balls .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gKH1ihBjiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLdZtfdEBxIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poRcbAaBAHsu",
        "colab_type": "code",
        "outputId": "256fb05a-406f-491d-f8a1-a40667e1ebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt , and a black hat , standing outside .\n",
            "A man in a blue shirt , is sitting on the ground .\n",
            "A man is sitting on the ground , while a woman watches .\n",
            "A man is sitting on the ground , while a woman watches .\n",
            "A man is working on the side of a building , and smiles .\n",
            "A man is working on the side of a building , and smiles .\n",
            "A man is working on a bench , while a woman watches him .\n",
            "A man is working on a bench , looking at the camera .\n",
            "A man is working on a bench , looking at the sky .\n",
            "A man is skiing down the street , looking at the sky .\n",
            "A man is skiing down the mountain , looking at the sky .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj4Bg5nUCUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtFK4SliCkmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQBaLTlClhM",
        "colab_type": "code",
        "outputId": "d515ed7e-20ed-4740-fcc4-dc34d65ee42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt is running through a field of grass .\n",
            "A man is walking in a field , holding a stick in thought .\n",
            "A man is walking in a field , holding a stick in thought .\n",
            "A man is standing in front of a large body of water .\n",
            "A man is standing in front of a large building , possibly .\n",
            "A man is standing in front of a large building , possibly .\n",
            "A man is standing in front of a large building , possibly .\n",
            "A man is standing in front of a large building , holding a bottle .\n",
            "A woman is walking down a slide , holding a camera in her mouth .\n",
            "A woman is walking down a street , holding a baby in her mouth .\n",
            "A woman is walking down the street , holding a baby .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYJ2ap7AYTWx",
        "colab_type": "text"
      },
      "source": [
        "Soft Free Bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5_nOgD-7mnL",
        "colab_type": "text"
      },
      "source": [
        "Ran for 2 hours and 15 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwnzy1OZyZsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, gamma, target_rate=4.0):\n",
        "  \"\"\"\n",
        "  Trains the model\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  running_loss = running_kl = running_re = total_kl = 0.0\n",
        "  num_seq = 0\n",
        "  gamma = gamma\n",
        "  for batch_idx, data in enumerate(batch_training):\n",
        "    _, seq_len = data.size()\n",
        "    num_seq += batch_size\n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    kl, re = model(data)\n",
        "    kl_sum = kl.sum()\n",
        "    re_sum = re.sum()\n",
        "    loss = kl_sum * gamma + re_sum\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    running_kl += kl_sum\n",
        "    running_re += re_sum\n",
        "    running_loss += kl_sum + re_sum\n",
        "  \n",
        "    if (epoch == 0 or epoch % 10 == 9) and  batch_idx % print_every == print_every-1:    \n",
        "      print('[%d, %5d] Train loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / num_seq))\n",
        "      print('[%d, %5d] Train KL: %.3f' % (epoch + 1, batch_idx + 1, running_kl / num_seq))\n",
        "      print('[%d, %5d] Train RE: %.3f' % (epoch + 1, batch_idx + 1, running_re / num_seq))\n",
        "  \n",
        "  total_kl = running_kl / num_seq\n",
        "  print('[%d] Anneal parameter: %.3f' % (epoch + 1, gamma))\n",
        "  if epoch < 10:\n",
        "    gamma = 0.1 * (epoch + 1)   \n",
        "  elif total_kl > 1.05 * target_rate:\n",
        "    gamma *= 1.1 \n",
        "    gamma = min(gamma, 1.0)\n",
        "  elif total_kl < 0.95 * target_rate:\n",
        "    gamma *= 0.9\n",
        "  \n",
        "  return gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHABiyZkABlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gamma = 0.0\n",
        "lr = 0.5\n",
        "optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "decay_learning = DecayLearning()\n",
        "num_decays = 0\n",
        "early_stop = 5\n",
        "clip_grad = 5.0\n",
        "\n",
        "for epoch in range(10):\n",
        "  gamma = train(epoch, gamma)\n",
        "  val_loss = test(epoch, True)\n",
        "  decay_learning(val_loss)\n",
        "  if decay_learning.update_lr:\n",
        "    lr *= 0.5\n",
        "    num_decays += 1\n",
        "    if num_decays == early_stop + 1:\n",
        "      print(\"Stopping early at epoch\", epoch+1)\n",
        "      break\n",
        "    print(\"Learning rate has been decayed to\", lr, \"at epoch\", epoch+1)\n",
        "    optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    decay_learning = DecayLearning()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUazMVIzOHQG",
        "colab_type": "code",
        "outputId": "859f8a19-913f-45bc-b448-5b51efa54782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "# epoch in range(10,20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11] Anneal parameter: 1.000\n",
            "[12] Anneal parameter: 0.900\n",
            "Learning rate has been decayed to 0.25 at epoch 12\n",
            "[13] Anneal parameter: 0.810\n",
            "[14] Anneal parameter: 0.729\n",
            "[15] Anneal parameter: 0.656\n",
            "Learning rate has been decayed to 0.125 at epoch 15\n",
            "[16] Anneal parameter: 0.590\n",
            "[17] Anneal parameter: 0.531\n",
            "[18] Anneal parameter: 0.531\n",
            "[19] Anneal parameter: 0.585\n",
            "[20,  3125] Train loss: 20.184\n",
            "[20,  3125] Train KL: 3.398\n",
            "[20,  3125] Train RE: 16.785\n",
            "[20,  6250] Train loss: 23.228\n",
            "[20,  6250] Train KL: 3.748\n",
            "[20,  6250] Train RE: 19.480\n",
            "[20,  9375] Train loss: 26.961\n",
            "[20,  9375] Train KL: 3.991\n",
            "[20,  9375] Train RE: 22.969\n",
            "[20, 12500] Train loss: 31.089\n",
            "[20, 12500] Train KL: 4.184\n",
            "[20, 12500] Train RE: 26.905\n",
            "[20] Anneal parameter: 0.643\n",
            "[20,  1248] Validation loss: 41.396\n",
            "[20,  1248] Validation KL: 5.070\n",
            "[20,  1248] Validation RE: 36.326\n",
            "Learning rate has been decayed to 0.0625 at epoch 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiXs-CARpy96",
        "colab_type": "code",
        "outputId": "2a77c345-d516-46cc-b9fc-1e9ab821262f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# epoch in range(20,30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21] Anneal parameter: 0.643\n",
            "[22] Anneal parameter: 0.707\n",
            "[23] Anneal parameter: 0.707\n",
            "[24] Anneal parameter: 0.707\n",
            "Learning rate has been decayed to 0.03125 at epoch 24\n",
            "[25] Anneal parameter: 0.707\n",
            "[26] Anneal parameter: 0.707\n",
            "[27] Anneal parameter: 0.707\n",
            "[28] Anneal parameter: 0.707\n",
            "[29] Anneal parameter: 0.707\n",
            "Learning rate has been decayed to 0.015625 at epoch 29\n",
            "[30,  3125] Train loss: 20.254\n",
            "[30,  3125] Train KL: 3.373\n",
            "[30,  3125] Train RE: 16.880\n",
            "[30,  6250] Train loss: 22.724\n",
            "[30,  6250] Train KL: 3.635\n",
            "[30,  6250] Train RE: 19.089\n",
            "[30,  9375] Train loss: 26.113\n",
            "[30,  9375] Train KL: 3.842\n",
            "[30,  9375] Train RE: 22.271\n",
            "[30, 12500] Train loss: 29.916\n",
            "[30, 12500] Train KL: 3.997\n",
            "[30, 12500] Train RE: 25.919\n",
            "[30] Anneal parameter: 0.707\n",
            "[30,  1248] Validation loss: 37.195\n",
            "[30,  1248] Validation KL: 4.265\n",
            "[30,  1248] Validation RE: 32.930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsIGc6uwxmad",
        "colab_type": "code",
        "outputId": "5407d5f8-3b99-448c-9240-1d3f70721d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# epoch in range(30,40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31] Anneal parameter: 0.707\n",
            "[32] Anneal parameter: 0.707\n",
            "[33] Anneal parameter: 0.707\n",
            "[34] Anneal parameter: 0.707\n",
            "[35] Anneal parameter: 0.707\n",
            "[36] Anneal parameter: 0.707\n",
            "Stopping early at epoch 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDXCxPF_3hoc",
        "colab_type": "code",
        "outputId": "8ba893ea-70a0-4ab7-b2eb-a592b849218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "test(35, False)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36,  1249] Test loss: 36.728\n",
            "[36,  1249] Test KL: 4.288\n",
            "[36,  1249] Test RE: 32.439\n",
            "[36,  1249] Test NLL: 36.728\n",
            "[36,  1249] Test PPL: 46.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(36.7276, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDI_hXSvbqph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "63c5b839-a4a0-4f32-df8e-bc6d64f9bdf9"
      },
      "source": [
        "importance_sampling_test()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NLL: 36.753\n",
            "Test PPL: 47.246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ScDElP5ZPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YKFJjLn5bSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m5wLPeD4teU",
        "colab_type": "code",
        "outputId": "b5b3f05b-f6d1-4f0c-d661-1ea4c3041782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man is looking at the camera , while others watch the camera .\n",
            "A man is looking at the camera , while others watch the camera .\n",
            "A man is holding a baby , while he is holding a weed-eater .\n",
            "A man is holding a baby , while he is holding a weed-eater .\n",
            "A man is holding a baby , while he is holding a weed-eater .\n",
            "A man is holding a baby , while he is holding a weed-eater .\n",
            "Two men are standing in front of a large crowd of people .\n",
            "Two men are playing with a toy in the snow , and they wait .\n",
            "Two men are playing with a toy in the snow , and they wait .\n",
            "Two men are playing with a toy in the snow , and they are outside .\n",
            "Two men are playing with a toy in the snow , and they are outside .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRunnbMv6QOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7v99zGX6RdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwIwfm1F6FIW",
        "colab_type": "code",
        "outputId": "8cd204c3-810d-41fd-c143-ff44c5321093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The woman is trying to be seen in the middle of a crowd .\n",
            "The woman is trying to get a speech to get a speech .\n",
            "A woman is trying to get a speech to get a speech .\n",
            "A young boy is trying to get a speech to get a speech .\n",
            "A young boy jumps into a pool , while others watch a <unk>lowercase .\n",
            "A young boy jumps into a pool , while others watch a race .\n",
            "A young boy jumps into a pool , while others watch a race .\n",
            "A young boy jumps into a pool , while others watch a race .\n",
            "A young boy jumps into a pool , while another watches the ball .\n",
            "A young boy jumps into a pool , while another watches the ball .\n",
            "A black dog runs through a field of a grassy field .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0JClpZq7GBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAg2XhTT7HAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq9M9PNB6v7a",
        "colab_type": "code",
        "outputId": "910c53b4-f888-474a-a182-e31d26c2c94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a red shirt is riding a bike in the rain .\n",
            "A man in a red shirt is riding a bike in the rain .\n",
            "A man in a red shirt is riding a bicycle on the street .\n",
            "A man in a red shirt is riding a bicycle on the street .\n",
            "A man in a red shirt is riding a bicycle on the street .\n",
            "A man in a red shirt is riding a bicycle on the street .\n",
            "The man is riding a bike down the street , wearing a helmet .\n",
            "The man is riding a bike down the street , wearing a helmet .\n",
            "The man is riding a bike down the street , wearing a helmet .\n",
            "The man is standing on the street , is working on the street .\n",
            "The man is standing on the street , is working on the street .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh8k_EZ39kWJ",
        "colab_type": "text"
      },
      "source": [
        "Baseline: Only KL Annealing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsLysU5oSCw5",
        "colab_type": "text"
      },
      "source": [
        "Ran for 1 hour and 15 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMdSp0yQ9if5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, target_rate=4.0):\n",
        "  \"\"\"\n",
        "  Trains the model\n",
        "  Helpful link for free bits: https://stats.stackexchange.com/questions/267924/explanation-of-the-free-bits-technique-for-variational-autoencoders\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  running_loss = running_kl = running_re = total_kl = 0.0\n",
        "  num_seq = 0\n",
        "  for batch_idx, data in enumerate(batch_training):\n",
        "    _, seq_len = data.size()\n",
        "    num_seq += batch_size\n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    kl, re = model(data)\n",
        "    kl_sum = kl.sum()\n",
        "    re_sum = re.sum()\n",
        "    gamma = 0.1 * epoch if epoch < 10 else 1.0\n",
        "    loss = kl_sum * gamma + re_sum\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    running_kl += kl_sum\n",
        "    running_re += re_sum\n",
        "    running_loss += kl_sum + re_sum\n",
        "  \n",
        "    if (epoch == 0 or epoch % 10 == 9) and  batch_idx % print_every == print_every-1:    \n",
        "      print('[%d, %5d] Train loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / num_seq))\n",
        "      print('[%d, %5d] Train KL: %.3f' % (epoch + 1, batch_idx + 1, running_kl / num_seq))\n",
        "      print('[%d, %5d] Train RE: %.3f' % (epoch + 1, batch_idx + 1, running_re / num_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vEV8q75-fGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "921037bf-df18-479f-eaa2-310d4e800cba"
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "decoder = Decoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "model = VAE(encoder, decoder)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "lr = 0.5\n",
        "optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "decay_learning = DecayLearning()\n",
        "num_decays = 0\n",
        "early_stop = 5\n",
        "clip_grad = 5.0\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(epoch)\n",
        "  val_loss = test(epoch, True)\n",
        "  decay_learning(val_loss)\n",
        "  if decay_learning.update_lr:\n",
        "    lr *= 0.5\n",
        "    num_decays += 1\n",
        "    if num_decays == early_stop + 1:\n",
        "      print(\"Stopping early at epoch\", epoch+1)\n",
        "      break\n",
        "    print(\"Learning rate has been decayed to\", lr, \"at epoch\", epoch+1)\n",
        "    optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    decay_learning = DecayLearning()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3125] Train loss: 55.123\n",
            "[1,  3125] Train KL: 32.204\n",
            "[1,  3125] Train RE: 22.919\n",
            "[1,  6250] Train loss: 72.044\n",
            "[1,  6250] Train KL: 47.011\n",
            "[1,  6250] Train RE: 25.032\n",
            "[1,  9375] Train loss: 84.807\n",
            "[1,  9375] Train KL: 56.620\n",
            "[1,  9375] Train RE: 28.187\n",
            "[1, 12500] Train loss: 95.835\n",
            "[1, 12500] Train KL: 64.056\n",
            "[1, 12500] Train RE: 31.779\n",
            "[1,  1248] Validation loss: 128.303\n",
            "[1,  1248] Validation KL: 92.782\n",
            "[1,  1248] Validation RE: 35.521\n",
            "[10,  3125] Train loss: 22.810\n",
            "[10,  3125] Train KL: 2.241\n",
            "[10,  3125] Train RE: 20.569\n",
            "[10,  6250] Train loss: 26.362\n",
            "[10,  6250] Train KL: 2.358\n",
            "[10,  6250] Train RE: 24.004\n",
            "[10,  9375] Train loss: 30.558\n",
            "[10,  9375] Train KL: 2.426\n",
            "[10,  9375] Train RE: 28.132\n",
            "[10, 12500] Train loss: 35.176\n",
            "[10, 12500] Train KL: 2.525\n",
            "[10, 12500] Train RE: 32.651\n",
            "[10,  1248] Validation loss: 40.219\n",
            "[10,  1248] Validation KL: 3.631\n",
            "[10,  1248] Validation RE: 36.588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffG8IjdxE3s8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "3e594a07-e0f4-4485-9959-0857c1a12570"
      },
      "source": [
        "# epoch in range(10, 20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.25 at epoch 18\n",
            "[20,  3125] Train loss: 19.828\n",
            "[20,  3125] Train KL: 0.052\n",
            "[20,  3125] Train RE: 19.775\n",
            "[20,  6250] Train loss: 23.130\n",
            "[20,  6250] Train KL: 0.054\n",
            "[20,  6250] Train RE: 23.076\n",
            "[20,  9375] Train loss: 27.003\n",
            "[20,  9375] Train KL: 0.056\n",
            "[20,  9375] Train RE: 26.947\n",
            "[20, 12500] Train loss: 31.280\n",
            "[20, 12500] Train KL: 0.057\n",
            "[20, 12500] Train RE: 31.223\n",
            "[20,  1248] Validation loss: 40.120\n",
            "[20,  1248] Validation KL: 0.205\n",
            "[20,  1248] Validation RE: 39.915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wBwcImJArf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "0ed8ee48-f2e1-48d8-b99f-9a747f3fd026"
      },
      "source": [
        "# epoch in range(20, 30)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.125 at epoch 21\n",
            "Learning rate has been decayed to 0.0625 at epoch 25\n",
            "[30,  3125] Train loss: 18.491\n",
            "[30,  3125] Train KL: 0.019\n",
            "[30,  3125] Train RE: 18.471\n",
            "[30,  6250] Train loss: 21.388\n",
            "[30,  6250] Train KL: 0.020\n",
            "[30,  6250] Train RE: 21.368\n",
            "[30,  9375] Train loss: 24.968\n",
            "[30,  9375] Train KL: 0.021\n",
            "[30,  9375] Train RE: 24.948\n",
            "[30, 12500] Train loss: 28.890\n",
            "[30, 12500] Train KL: 0.021\n",
            "[30, 12500] Train RE: 28.869\n",
            "[30,  1248] Validation loss: 40.555\n",
            "[30,  1248] Validation KL: 0.028\n",
            "[30,  1248] Validation RE: 40.527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc3dvnaDMmUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2438f5d4-f65b-449f-bfbb-27c553e53f2c"
      },
      "source": [
        "# epoch in range(30, 40)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.03125 at epoch 32\n",
            "Learning rate has been decayed to 0.015625 at epoch 38\n",
            "[40,  3125] Train loss: 18.659\n",
            "[40,  3125] Train KL: 0.014\n",
            "[40,  3125] Train RE: 18.645\n",
            "[40,  6250] Train loss: 21.346\n",
            "[40,  6250] Train KL: 0.015\n",
            "[40,  6250] Train RE: 21.331\n",
            "[40,  9375] Train loss: 24.758\n",
            "[40,  9375] Train KL: 0.015\n",
            "[40,  9375] Train RE: 24.743\n",
            "[40, 12500] Train loss: 28.582\n",
            "[40, 12500] Train KL: 0.015\n",
            "[40, 12500] Train RE: 28.567\n",
            "[40,  1248] Validation loss: 36.534\n",
            "[40,  1248] Validation KL: 0.018\n",
            "[40,  1248] Validation RE: 36.515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRVnmQB0QY7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad0342d0-9451-4302-fcd8-a5833a977dad"
      },
      "source": [
        "# epoch in range(40, 50)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping early at epoch 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvfpUePnNL2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "32e76533-10f0-4d65-b2e9-33152f112255"
      },
      "source": [
        "test(41, False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[42,  1249] Test loss: 36.057\n",
            "[42,  1249] Test KL: 0.017\n",
            "[42,  1249] Test RE: 36.041\n",
            "[42,  1249] Test NLL: 36.057\n",
            "[42,  1249] Test PPL: 43.805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(36.0575, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vZo79IriQVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "206f7cb5-e088-41a5-80fe-39359378ef1f"
      },
      "source": [
        "importance_sampling_test()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NLL: 37.124\n",
            "Test PPL: 49.119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t_ki-n5JKm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkfh5uH-NqqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErABkHSsJPV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "fc94226a-137a-4416-9119-7c646c69c1f8"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black hat smiles .\n",
            "A man in a blue shirt , and a black hat smiles .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUbN3uJui5XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3KlsypCi8z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaT9M1eojAMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "750e6456-9e5b-4369-cdbc-8ec5209b7b40"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt is standing in a park bench .\n",
            "A man in a blue shirt , and a black shirt , smiling .\n",
            "A man in a blue shirt , and a black shirt , smiling .\n",
            "A man in a blue shirt , and a black shirt , smiling .\n",
            "A man in a blue shirt , and a black shirt , smiling .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl3lnUpwjF0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwmAHpIrjH53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8kVRKDHjJrn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "3af67e23-e731-483f-9a67-1be4320219e2"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt , and a black hat , smile .\n",
            "A man in a blue shirt , and a black hat , smile .\n",
            "A man in a blue shirt , and a black hat , smile .\n",
            "A man in a blue shirt , and a black hat , smiling .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n",
            "A man in a blue shirt , and a black shirt smiles .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwHYfzR53pD0",
        "colab_type": "text"
      },
      "source": [
        "Pretraining and KL Annealing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggxrlAhYI95d",
        "colab_type": "text"
      },
      "source": [
        "Ran for 2.75 hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_x9syrj3m8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "  \"\"\"\n",
        "  Trains the model\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  running_loss = running_kl = running_re = total_kl = 0.0\n",
        "  num_seq = 0\n",
        "  gamma = 0.1 * epoch if epoch < 10 else 1.0\n",
        "  for batch_idx, data in enumerate(batch_training):\n",
        "    batch_size, seq_len = data.size()\n",
        "    num_seq += batch_size\n",
        "    optimizer_e.zero_grad()\n",
        "    optimizer_d.zero_grad()\n",
        "    kl, re = model(data)\n",
        "    kl_sum = kl.sum()\n",
        "    re_sum = re.sum()\n",
        "    loss = kl_sum * gamma + re_sum\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "    optimizer_e.step()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    running_kl += kl_sum\n",
        "    running_re += re_sum\n",
        "    running_loss += kl_sum + re_sum\n",
        "  \n",
        "    if (epoch == 0 or epoch % 10 == 9) and  batch_idx % print_every == print_every-1:    \n",
        "      print('[%d, %5d] Train loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / num_seq))\n",
        "      print('[%d, %5d] Train KL: %.3f' % (epoch + 1, batch_idx + 1, running_kl / num_seq))\n",
        "      print('[%d, %5d] Train RE: %.3f' % (epoch + 1, batch_idx + 1, running_re / num_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdal8PPd4yyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "fb66936c-2819-461a-e747-8fbb669ea390"
      },
      "source": [
        "lr = 0.5\n",
        "optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "\n",
        "decay_learning = DecayLearning()\n",
        "num_decays = 0\n",
        "early_stop = 5\n",
        "clip_grad = 5.0\n",
        "\n",
        "for epoch in range(10):\n",
        "  train(epoch)\n",
        "  val_loss = test(epoch, True)\n",
        "  decay_learning(val_loss)\n",
        "  if decay_learning.update_lr:\n",
        "    lr *= 0.5\n",
        "    num_decays += 1\n",
        "    if num_decays == early_stop + 1:\n",
        "      print(\"Stopping early at epoch\", epoch+1)\n",
        "      break\n",
        "    print(\"Learning rate has been decayed to\", lr, \"at epoch\", epoch+1)\n",
        "    optimizer_e = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    optimizer_d = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    decay_learning = DecayLearning()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3125] Train loss: 146.450\n",
            "[1,  3125] Train KL: 130.960\n",
            "[1,  3125] Train RE: 15.490\n",
            "[1,  6250] Train loss: 142.970\n",
            "[1,  6250] Train KL: 125.994\n",
            "[1,  6250] Train RE: 16.976\n",
            "[1,  9375] Train loss: 141.517\n",
            "[1,  9375] Train KL: 121.478\n",
            "[1,  9375] Train RE: 20.039\n",
            "[1, 12500] Train loss: 142.503\n",
            "[1, 12500] Train KL: 118.690\n",
            "[1, 12500] Train RE: 23.814\n",
            "[1,  1248] Validation loss: 140.490\n",
            "[1,  1248] Validation KL: 114.191\n",
            "[1,  1248] Validation RE: 26.300\n",
            "[10,  3125] Train loss: 23.345\n",
            "[10,  3125] Train KL: 2.323\n",
            "[10,  3125] Train RE: 21.022\n",
            "[10,  6250] Train loss: 26.941\n",
            "[10,  6250] Train KL: 2.352\n",
            "[10,  6250] Train RE: 24.588\n",
            "[10,  9375] Train loss: 31.270\n",
            "[10,  9375] Train KL: 2.470\n",
            "[10,  9375] Train RE: 28.800\n",
            "[10, 12500] Train loss: 35.974\n",
            "[10, 12500] Train KL: 2.593\n",
            "[10, 12500] Train RE: 33.380\n",
            "[10,  1248] Validation loss: 41.923\n",
            "[10,  1248] Validation KL: 3.049\n",
            "[10,  1248] Validation RE: 38.874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS4ug_-cEE0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "0c235c18-2bb4-493e-8dca-7546d58a89cb"
      },
      "source": [
        "# for epoch in range(10,20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.25 at epoch 17\n",
            "[20,  3125] Train loss: 19.816\n",
            "[20,  3125] Train KL: 0.040\n",
            "[20,  3125] Train RE: 19.777\n",
            "[20,  6250] Train loss: 23.105\n",
            "[20,  6250] Train KL: 0.039\n",
            "[20,  6250] Train RE: 23.066\n",
            "[20,  9375] Train loss: 26.997\n",
            "[20,  9375] Train KL: 0.040\n",
            "[20,  9375] Train RE: 26.957\n",
            "[20, 12500] Train loss: 31.258\n",
            "[20, 12500] Train KL: 0.042\n",
            "[20, 12500] Train RE: 31.217\n",
            "[20,  1248] Validation loss: 43.467\n",
            "[20,  1248] Validation KL: 0.062\n",
            "[20,  1248] Validation RE: 43.405\n",
            "Learning rate has been decayed to 0.125 at epoch 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2EppstuKYzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2236778e-9122-49db-b8af-c20135cf08a3"
      },
      "source": [
        "# for epoch in range(20,30)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.0625 at epoch 24\n",
            "[30,  3125] Train loss: 18.532\n",
            "[30,  3125] Train KL: 0.011\n",
            "[30,  3125] Train RE: 18.521\n",
            "[30,  6250] Train loss: 21.440\n",
            "[30,  6250] Train KL: 0.011\n",
            "[30,  6250] Train RE: 21.429\n",
            "[30,  9375] Train loss: 25.058\n",
            "[30,  9375] Train KL: 0.012\n",
            "[30,  9375] Train RE: 25.046\n",
            "[30, 12500] Train loss: 29.008\n",
            "[30, 12500] Train KL: 0.012\n",
            "[30, 12500] Train RE: 28.996\n",
            "[30,  1248] Validation loss: 41.166\n",
            "[30,  1248] Validation KL: 0.019\n",
            "[30,  1248] Validation RE: 41.147\n",
            "Learning rate has been decayed to 0.03125 at epoch 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec1A8ZnFTxBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d40aeff9-3f15-455e-99f0-c25dc5834aff"
      },
      "source": [
        "# for epoch in range(30,40)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate has been decayed to 0.015625 at epoch 37\n",
            "[40,  3125] Train loss: 18.741\n",
            "[40,  3125] Train KL: 0.007\n",
            "[40,  3125] Train RE: 18.734\n",
            "[40,  6250] Train loss: 21.417\n",
            "[40,  6250] Train KL: 0.008\n",
            "[40,  6250] Train RE: 21.410\n",
            "[40,  9375] Train loss: 24.881\n",
            "[40,  9375] Train KL: 0.008\n",
            "[40,  9375] Train RE: 24.874\n",
            "[40, 12500] Train loss: 28.737\n",
            "[40, 12500] Train KL: 0.008\n",
            "[40, 12500] Train RE: 28.729\n",
            "[40,  1248] Validation loss: 36.793\n",
            "[40,  1248] Validation KL: 0.010\n",
            "[40,  1248] Validation RE: 36.783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Gdp3fgcA_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "629ff14e-76f8-47dc-a28c-2d3c3ff544f9"
      },
      "source": [
        "# for epoch in range(40,50)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping early at epoch 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHc61_ychBCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "35707c2d-faeb-442d-e0ed-cc1ef8c10b39"
      },
      "source": [
        "test(45, False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[46,  1249] Test loss: 36.274\n",
            "[46,  1249] Test KL: 0.009\n",
            "[46,  1249] Test RE: 36.266\n",
            "[46,  1249] Test NLL: 36.274\n",
            "[46,  1249] Test PPL: 44.813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(36.2745, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbDH5ypUhbsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7be42360-f851-4519-e16c-e8e1326445c3"
      },
      "source": [
        "importance_sampling_test()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test NLL: 37.376\n",
            "Test PPL: 50.435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "danwpX7ymQZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-j3hOemYKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRZvXx--mm2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "f17c65a1-9e24-44e9-fed4-cb8f613428ef"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjuUs2Yomuw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl5Ws3kHmyzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHUsFuom4EF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "11d64092-02f5-4201-c1a8-093629d7e4c2"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n",
            "A man is standing in front of a building , and smiles .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sNZIauBnB5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample1 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEuf9ZiQnE3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample2 = torch.randn(1, latent_size, device=cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEjbekZnHgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "abf722dc-5f68-418d-b90e-7250034ac757"
      },
      "source": [
        "interpolate(latent_size, sample1, sample2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a city street .\n",
            "A man in a blue shirt is standing in a chair , and smiles .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXpN3zx9krjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# Training\n",
        "f = open('./snli_1.0/snli_1.0_train.txt')\n",
        "contents = f.read()\n",
        "file_as_list = contents.splitlines()\n",
        "sentences = []\n",
        "for example in file_as_list[1:]:\n",
        "    sentence1 = example.split('\\t')[5]\n",
        "    sentence2 = example.split('\\t')[6]\n",
        "    sent1_len = len(sentence1.split())\n",
        "    sent2_len = len(sentence2.split())\n",
        "    if sent1_len <= 12: sentences.append(sentence1)\n",
        "    if sent2_len <= 12: sentences.append(sentence2)\n",
        "\n",
        "sample = random.sample(sentences, 50000)\n",
        "\n",
        "f = open('./snli_1.0/sample_train.txt', \"w\")\n",
        "for sentence in sample:\n",
        "    f.write(sentence)\n",
        "    f.write(\"\\n\")\n",
        "f.close()\n",
        "\n",
        "# Development\n",
        "f = open('./snli_1.0/snli_1.0_dev.txt')\n",
        "contents = f.read()\n",
        "file_as_list = contents.splitlines()\n",
        "sentences = []\n",
        "for example in file_as_list[1:]:\n",
        "    sentence1 = example.split('\\t')[5]\n",
        "    sentence2 = example.split('\\t')[6]\n",
        "    sent1_len = len(sentence1.split())\n",
        "    sent2_len = len(sentence2.split())\n",
        "    if sent1_len <= 12: sentences.append(sentence1)\n",
        "    if sent2_len <= 12: sentences.append(sentence2)\n",
        "\n",
        "sample = random.sample(sentences, 5000)\n",
        "\n",
        "f = open('./snli_1.0/sample_dev.txt', \"w\")\n",
        "for sentence in sample:\n",
        "    f.write(sentence)\n",
        "    f.write(\"\\n\")\n",
        "f.close()\n",
        "\n",
        "# Test\n",
        "f = open('./snli_1.0/snli_1.0_test.txt')\n",
        "contents = f.read()\n",
        "file_as_list = contents.splitlines()\n",
        "sentences = []\n",
        "for example in file_as_list[1:]:\n",
        "    sentence1 = example.split('\\t')[5]\n",
        "    sentence2 = example.split('\\t')[6]\n",
        "    sent1_len = len(sentence1.split())\n",
        "    sent2_len = len(sentence2.split())\n",
        "    if sent1_len <= 12: sentences.append(sentence1)\n",
        "    if sent2_len <= 12: sentences.append(sentence2)\n",
        "\n",
        "sample = random.sample(sentences, 5000)\n",
        "\n",
        "f = open('./snli_1.0/sample_test.txt', \"w\")\n",
        "for sentence in sample:\n",
        "    f.write(sentence)\n",
        "    f.write(\"\\n\")\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzXYJE1A1a-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'pt_kla.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "checkpoint = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_mDfHqJ7-9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "decoder = Decoder(vocab_size, embedding_size, hidden_size, latent_size)\n",
        "model = VAE(encoder, decoder)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXve6oGnSkaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "a608ee25-2c23-4979-a836-a68ae8781a7c"
      },
      "source": [
        "x1 = [10,20,30,36]\n",
        "x2 = [10,20,30,40]\n",
        "KL_SFB = [4.244, 5.07, 4.265, 4.265]\n",
        "KL_FB = [8.09, 5.381, 5.076, 4.883]\n",
        "KL_KA = [3.631,0.205, 0.028, 0.018]\n",
        "plt.scatter(x1,KL_SFB, s=100, alpha=0.5, label = \"PT+KLA+SFB\")\n",
        "plt.scatter(x2,KL_FB, s=100, alpha=0.5, label = \"PT+KLA+FB\")\n",
        "plt.scatter(x2, KL_KA, s=100,alpha=0.5, label=\"KLA\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('KL')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBbyIiE8p4EVEfEoBLyLiUwp4ERGf+v9MeSpEmWBWnwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}