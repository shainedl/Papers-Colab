{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational_Principal_Components.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shainedl/Papers-Colab/blob/master/Variational_Principal_Components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDsLw_WLUCcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.special as sp\n",
        "from scipy.stats import multivariate_normal \n",
        "from scipy.stats import gamma "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCND_ufcSiGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BayesianPCA():\n",
        "  \n",
        "  def __init__(self, a_alpha=10e-3, b_alpha=10e-3, a_tau=10e-3, b_tau=10e-3, beta=10e-3):\n",
        "    \n",
        "    # hyperparameters\n",
        "    self.a_alpha = a_alpha\n",
        "    self.b_alpha = b_alpha\n",
        "    self.a_tau = a_tau\n",
        "    self.b_tau = b_tau\n",
        "    self.beta = beta \n",
        "    \n",
        "    # variational parameters\n",
        "    self.mean_x = np.random.randn(self.q, self.N)\n",
        "    self.sigma_x = np.identity(self.q)\n",
        "    self.mean_mu = np.random.randn(self.d, 1)\n",
        "    self.sigma_mu = np.identity(self.d)\n",
        "    self.mean_w = np.random.randn(self.d, self.q)\n",
        "    self.sigma_w = np.identity(self.q)\n",
        "    self.a_alpha_tilde = self.a_alpha + self.d / 2\n",
        "    self.b_alpha_tilde = np.abs(np.random.randn(self.q))\n",
        "    self.a_tau_tilde = self.a_tau + self.N * self.d / 2\n",
        "    self.b_tau_tilde = np.abs(np.random.randn(1))\n",
        "     \n",
        "  def __reestimate(self):\n",
        "    \n",
        "    # observation parameter\n",
        "    self.tau = self.a_tau_tilde / self.b_tau_tilde\n",
        "\n",
        "    # latent variables\n",
        "    self.sigma_x = np.linalg.inv(np.identity(self.q) + self.tau *\n",
        "                   (np.trace(self.sigma_w) + np.dot(self.mean_w.T, self.mean_w)))\n",
        "    self.mean_x = self.tau * np.dot(np.dot(self.sigma_x, self.mean_w.T),(self.t_n - self.mean_mu)\n",
        "    \n",
        "    # observation parameter                                \n",
        "    self.sigma_mu = np.identity(self.d) / (self.beta + self.N * self.tau)\n",
        "    self.mean_mu = self.tau * np.dot(self.sigma_mu, np.sum(self.t_n - np.dot(self.mean_w, self.mean_x))\n",
        "    \n",
        "    # hyperparameter controlling the columns of W\n",
        "    self.alpha = self.a_alpha_tilde / self.b_alpha_tilde\n",
        "                                     \n",
        "    # weight                                 \n",
        "    self.sigma_w = np.linalg.inv(np.diag(self.alpha) + self.tau * \n",
        "                   (self.N * self.sigma_x + np.dot(self.mean_x, mean_x.T))\n",
        "    self.mean_w = self.tau * np.dot(self.sigma_w, np.dot(self.mean_x, (self.t_n - self.mean_mu)))\n",
        "    \n",
        "    # alpha's gamma distribution parameter                            \n",
        "    self.b_alpha_tilde = self.b_alpha + 0.5 * (np.trace(self.sigma_w) + \n",
        "                         np.dot(self.mean_w, self.mean_w))\n",
        "                                                            \n",
        "    # tau's gamma distribution parameter     \n",
        "    self.b_tau_tilde = self.b_tau + 0.5 * np.sum(np.dot(self.t_n, self.t_n)) + \n",
        "                       0.5 * self.N * (np.trace(self.sigma_mu) + np.dot(self.mean_mu, self.mean_mu)) + \n",
        "                       0.5 * np.trace(np.dot(np.trace(self.sigma_w) + \n",
        "                             np.dot(self.mean_w.T, self.mean_w), self.N * self.sigma_x + \n",
        "                             np.dot(self.mean_x, self.mean_x.T))) +\n",
        "                       np.sum(np.dot(np.dot(self.mean_mu.T, self.mean_w), self.mean_x)) -\n",
        "                       np.sum(np.dot(np.dot(t_n.T, self.mean_w), self.mean_x)) -\n",
        "                       np.sum(np.dot(t_n.T, self.mean_mu))          \n",
        "  \n",
        "  def __get_elbo(self):\n",
        "                                 \n",
        "    # random sample\n",
        "    x = np.random.multivariate_normal(self.mean_x, self.cov_x)\n",
        "    mu = np.random.multivariate_normal(self.mean_mu, self.cov_mu)\n",
        "    w = np.random.multivariate_normal(self.mean_w, self.cov_w) \n",
        "    alpha = np.random.gamma(self.a_alpha_tilde, 1 / self.b_alpha_tilde)     \n",
        "    tau = np.random.gamma(self.a_tau_tilde, 1 / self.b_tau_tilde)                             \n",
        "                                 \n",
        "    # priors\n",
        "    # p(x) = N(x|0,I_q)\n",
        "    prior = np.sum(multivariate_normal.logpdf(np.asarray(x).flatten(), np.zeros(self.q), np.identity(self.q)))\n",
        "      \n",
        "    # p(w|alpha) = conditional distribution                   \n",
        "    prior += np.sum(np.asarray((self.d / 2) * (np.log(alpha[i] / (2 * np.pi)) - 0.5 * alpha[i] * np.sum(np.power(w[:,i],2)) for i in range(self.q))                  \n",
        "                                 \n",
        "    # p(alpha) = Gamma(a, b)                             \n",
        "    prior += np.sum(gamma.logpdf(alpha, self.a_alpha, scale=1/self.b_alpha)                             \n",
        "                                 \n",
        "    # p(mu) = N(mu|0,Beta^-1I)        \n",
        "    prior += np.sum(multivariate_normal.logpdf(np.asarray(mu).flatten(), np.zeros(self.d), np.identity(self.d)/self.beta)) \n",
        "                    \n",
        "    # p(tau) = Gamma(c, d)      \n",
        "    prior += np.sum(gamma.logpdf(tau, self.a_tau, scale=1/self.b_tau) \n",
        "        \n",
        "                    \n",
        "    # log likelihood of the conditional distribution \n",
        "    # p(t_n | x_n, W, mu, tau)\n",
        "    likelihood = np.sum(multivariate_normal.logpdf(np.asarray(self.t_n).flatten(), np.asarray(np.dot(w, z) + mu).flatten(), np.identity(self.d) / tau))                 \n",
        "             \n",
        "                                   \n",
        "    # entropy\n",
        "    # q(x) \n",
        "    entropy = self.N * (0.5 * np.log(np.linalg.det(self.sigma_x) + (self.d / 2) * (1 + np.log(2 * np.pi)))     \n",
        "                       \n",
        "    # q(mu)\n",
        "    entropy += 0.5 * np.log(np.linalg.det(self.sigma_mu) + (self.d / 2) * (1 + np.log(2 * np.pi)) \n",
        "                            \n",
        "    # q(W)          \n",
        "    entropy += self.d * (0.5 * np.log(np.linalg.det(self.sigma_w) + (self.d / 2) * (1 + np.log(2 * np.pi)))  \n",
        "                         \n",
        "    # q(alpha)\n",
        "    entropy += self.q * (np.log(sp.gamma(self.a_alpha_tilde)) - (self.a_alpha_tilde - 1)\n",
        "                        * sp.digamma(self.a_alpha_tilde) - np.log(self.b_alpha_tilde) \n",
        "                        + self.a_alpha_tilde)  \n",
        "                         \n",
        "    # q(tau)   \n",
        "    entropy += np.log(sp.gamma(self.a_tau_tilde)) - (self.a_tau_tilde - 1)\n",
        "                        * sp.digamma(self.a_tau_tilde) - np.log(self.b_tau_tilde) \n",
        "                        + self.a_tau_tilde     \n",
        "                         \n",
        "    return prior + likelihood - entropy   \n",
        "                         \n",
        "  def fit(t_n, iterations = 10):\n",
        "    self.t_n = t_n\n",
        "    self.d = self.t_n.shape[0]                     \n",
        "    self.q = self.d - 1\n",
        "    self.N = self.t_n.shape[1]   \n",
        "                         \n",
        "    for i in range(iterations):\n",
        "      self.__reestimate()\n",
        "      elbo = self.__get_elbo()\n",
        "      print(\"Iterations: %d\", i)                   \n",
        "      print(\"ELBO: %d\", elbo)                   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNmSIgRA7U_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}